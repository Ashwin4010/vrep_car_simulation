# V-REP Car Simulation

## Introdution
The aim of this project is to simulate and control one or more cars in V-REP using ROS. This is part of the [Open Source Self-Driving Car Initiative](http://ossdc.org/join) (see in GitHub https://github.com/OSSDC/). 

The mission of this initiative and open organization is to bring the best research in self-driving car space and create a full stack of open source software and hardware components to allow anyone to build and test from toy to full-size self-driving cars.

We are investigating several solutions, like Unity3D, a PS3/PS4 simulator and V-REP, to check their advantages and drawbacks.

## V-REP and ROS
V-Rep is a General purpose 3D robot simulator with integrated development environment developed by <a href="http://www.coppeliarobotics.com/" target="_parent">Coppelia Robotics</a>. Sensors, mechanisms, robots and whole systems can be modeled and simulated in various ways.
 
There are several ROS interfaces available for V-REP: see [here](http://www.coppeliarobotics.com/helpFiles/en/rosInterfaces.htm). You could use the [RosInterface](http://www.coppeliarobotics.com/helpFiles/en/rosInterf.htm), but in this case, you should program in LUA to apply the command coming from ROS (you can do it directly in V-REP using the [embedded script](http://www.coppeliarobotics.com/helpFiles/en/scripts.htm) that you can associate with any object in the scene). 


In this case, I used the [VREP ROS Bridge](https://github.com/lagadic/vrep_ros_bridge/tree/master), mainly because the functionalities I needed are already implemented. 

We need to:
* publish images coming from a vision sensor
* apply a twist velocity to an object with respect to its frame.

## Installation:

To test the scene, you will need to follow [this tutorial](https://github.com/lagadic/vrep_ros_bridge/tree/master). You will install ROS, V-REP and the V-REP Ros Bridge. 

## Run the simulation 
Remember to run `roscore` in another terminal before launching V-REP.   

Now you can run V-REP and open the scene `roads_car_ros`.

![Alt text](https://github.com/jokla/vrep_car_simulation/blob/master/scenes/vrep_cars.png?raw=true "Optional Title")


When you play start, the plugin will:
* publish images coming generated by the vision sensor placed on the white car (in the topic `/vrep/CameraTop`)
* subscribe to a velocity twist command to move the red car (in the topic `/vrep/car0/SetTwist`)

If you type `rostopic list` in a terminal you should see:

```
jokla@Dell-PC:~$ rostopic list
/rosout
/rosout_agg
/tf
/vrep/CameraTop
/vrep/CameraTop/compressed
/vrep/CameraTop/compressed/parameter_descriptions
/vrep/CameraTop/compressed/parameter_updates
/vrep/CameraTop/compressedDepth
/vrep/CameraTop/compressedDepth/parameter_descriptions
/vrep/CameraTop/compressedDepth/parameter_updates
/vrep/CameraTop/theora
/vrep/CameraTop/theora/parameter_descriptions
/vrep/CameraTop/theora/parameter_updates
/vrep/camera_info
/vrep/car/SetTwist
/vrep/car0/SetTwist
/vrep/info

```


You can find the model of the car [here](http://tf3dm.com/3d-model/car-white-61307.html), and the model of the roads [here](http://tf3dm.com/download-page.php?url=street-system-v10-48448).


## Move a car using a joystick
Now we want to generate a velocity command using a joystick. We will use the node [https://github.com/jokla/teleop_twist_joy](https://github.com/jokla/teleop_twist_joy) and a PS4 Joystick ( but you can use any joystick working under Ubuntu).

* Clone in your source catkin_ws folder the package `teleop_twist_joy`:
 * `$ git clone git@github.com:jokla/teleop_twist_joy.git`    
 * Run a `catkin_make`  

To check if the joystick is working under Ubuntu you can install `jstest-gtk`:   
* `$ sudo apt-get install jstest-gtk`   
You can also check this tutorial: [ConfiguringALinuxJoystick](http://wiki.ros.org/joy/Tutorials/ConfiguringALinuxJoystick)   

Now you can try to launch the node ():   
`roslaunch teleop_twist_joy teleop-ps4.launch`   
This node will publish in two topics:

```
/joy
/vrep/car0/SetTwist
```

If you run the scene in V-REP, you should be able to move the red car. You have to keep L1 pressed and after use the two thumbsticks to apply a linear velocity vx (right thumbstick - up and down) and angular velocity wz (right thumbstick - left and right).

You can change the buttons and axis modifying [this configuration file](https://github.com/jokla/teleop_twist_joy/blob/indigo-devel/config/ps4.config.yaml). 

##Test OpenTLD 

TLD = Robust Object Tracking Based on Tracking-Learning-Detection

You will need to clone the following two packages in your `catkin_ws`:   
`$ git clone https://github.com/pandora-auth-ros-pkg/open_tld`
`$ git clone https://github.com/pandora-auth-ros-pkg/pandora_tld`

After do a catkin_make and open the file [`/config/predator_topics.yaml`](https://github.com/pandora-auth-ros-pkg/pandora_tld/blob/master/config/predator_topics.yaml)

You will need to modify the name of the `input_image_topic` with `/vrep/CameraTop`.

To launch the node:
`roslaunch pandora_tld predator_node.launch`

A image window should appear, read [here](https://github.com/pandora-auth-ros-pkg/open_tld) to have more info about the Keyboard shortcuts. 

This is the result:   

[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/Si8w4eYzhis/0.jpg)](https://www.youtube.com/watch?v=Si8w4eYzhis)


Tutorial: https://github.com/rapp-project/rapp-platform/wiki/Remote-application-for-NAO-in-Python:-Use-ROS-&-TLD-tracker-to-approach-arbitrary-objects-(hard)

## Future work:
* Simulate the Ackermann steering mechanism. Right now the car is just a static object. There is simple model in V-REP under the folder `example`
* Add other sensors, like a lidar.
